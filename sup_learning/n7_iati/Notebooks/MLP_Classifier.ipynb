{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8876b77-e0d9-4533-98a7-e85505558a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6337ab7-2e96-4617-85fb-7512d7d3d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b43663-cf32-4002-a97e-e0e6dbbca347",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "We first need to prepare the data set: download the data, split train/val set and do normalisation. This part is taken from https://teaching.pages.centralesupelec.fr/deeplearning-lectures-build/00-pytorch-fashionMnist.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1bdfc21-1971-4e3c-b383-783331b1162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the data\n",
    "# Change path accordingly\n",
    "dataset_dir = \"/home/mfauvel/Documents/Data/FashionMNIST\"\n",
    "train_valid_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=dataset_dir, train=True, transform=None, download=True\n",
    ")\n",
    "train_dataset, valid_dataset = torch.utils.data.dataset.random_split(\n",
    "    train_valid_dataset, [0.8, 0.2]\n",
    ")\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=dataset_dir, transform=None, train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cae0c7c-ccb2-40a2-a5d7-a37a3f32c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compute the normalisation\n",
    "ToTensor = transforms.ToTensor()  # Transform pil image to pytorch Tensor\n",
    "mean_ = torch.zeros_like(ToTensor(train_dataset[0][0]))\n",
    "std_ = torch.zeros_like(ToTensor(train_dataset[0][0]))\n",
    "for img, _ in train_dataset:\n",
    "    mean_ += ToTensor(img)\n",
    "mean_ /= len(train_dataset)\n",
    "for img, _ in train_dataset:\n",
    "    std_ += (mean_ - ToTensor(img)) ** 2\n",
    "std_ /= len(train_dataset)\n",
    "std_ = torch.sqrt(std_)\n",
    "std_[std_ == 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a7263c2-dd72-4837-9ee6-6f85843931ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prepare pytorch dataset\n",
    "class DatasetTransformer(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_dataset, transform):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.base_dataset[index]\n",
    "        return self.transform(img), target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Lambda(lambda x: (x - mean_) / std_)]\n",
    ")\n",
    "train_dataset = DatasetTransformer(train_dataset, data_transforms)\n",
    "valid_dataset = DatasetTransformer(valid_dataset, data_transforms)\n",
    "test_dataset = DatasetTransformer(test_dataset, data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04cdcc53-2805-4f99-8266-04ba46dcd641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Prepare data loader\n",
    "num_threads = 4  # Loading the dataset is using 4 CPU threads\n",
    "batch_size = 512  # Using minibatches of 512 samples\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_threads\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    dataset=valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_threads\n",
    ")\n",
    "\\section{Transformer}\n",
    "\n",
    "\\subsection{Attention}\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_threads\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a3b96-ffef-4dce-8a00-7545878c05ec",
   "metadata": {},
   "source": [
    "#Â Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb7ffd-72d2-493a-96c4-d679c73436b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassificationModel(nn.Module):\n",
    "    def __init__(self, n_features: int, n_classes: int):\n",
    "        super(MLPClassificationModel, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.n_classes = n_classes\n",
    "        self.layers = # TBC\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        X = X.view(\n",
    "            X.size()[0], -1\n",
    "        )  # reshape the data as a long vector [batch_size, n_feature]\n",
    "        y = self.layers(X)\n",
    "        return y\n",
    "\n",
    "    def predict_proba(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        y = self.forward(X)\n",
    "        p = self.softmax(y)\n",
    "        return p\n",
    "\n",
    "    def predict(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        p = self.forward(X)\n",
    "        c = torch.argmax(p, dim=1)\n",
    "        return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb0eb8-c978-4c50-a23d-a4f943161383",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5139efc-e813-4840-8d42-e378bebe72d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "learning_rate = 0.0001\n",
    "model = MLPClassificationModel(28 * 28, 10)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_set_len = len(train_loader)\n",
    "val_set_len = len(valid_loader)\n",
    "train_loss, val_loss = [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    accu = 0.0\n",
    "\n",
    "    for X_, y_ in train_loader:\n",
    "        # Forward pass\n",
    "        y_hat = model(X_)\n",
    "        loss = loss_fn(y_hat, y_)\n",
    "        accu += loss.item()\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss.append(accu / train_set_len)\n",
    "\n",
    "    # Validation - no gradient & eval mode\n",
    "    model.eval()\n",
    "    accu = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_, y_ in valid_loader:\n",
    "            # Forward pass\n",
    "            y_hat = model(X_)\n",
    "            loss = loss_fn(y_hat, y_)\n",
    "            accu += loss.item()\n",
    "        val_loss.append(accu / val_set_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f92feb5-b688-4df6-b7af-24651826e03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014ffe90-9a94-41ef-bc6c-73a1649f31e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "acc = 0.0\n",
    "with torch.no_grad():\n",
    "    for X_, y_ in test_loader:\n",
    "        y_hat = model.predict(X_)\n",
    "        acc += (y_ == y_hat).sum().item()\n",
    "    acc /= len(test_dataset)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ad0d3-0c00-4dca-aea2-4809c597d6cc",
   "metadata": {},
   "source": [
    "# To Do\n",
    "- Compute the classification accuracy with the model\n",
    "- Take a wrongly classified image, and look at the probability membership for each class.\n",
    "- Implement dropout and train again.\n",
    "- Implement a check to save the best model w.r.t the validation loss and compare the accuracy of the \"best\" model with the \"last\" model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
