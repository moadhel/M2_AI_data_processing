{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b435f12-95be-4235-a655-6f912183a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aa9ac5-7352-457a-bc7f-967ecf98a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137f13f-9fa9-4967-ae7f-0e054c1ec21d",
   "metadata": {},
   "source": [
    "# Prepare the data set\n",
    "Split data into three sub-data set: (train, val) and test. The latter will be used to test the model accuracy once the full model is learned. The formers will be used to train the model and evaluate the convergence/overfitting along the iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764343ac-e748-4a5b-a205-f03a978810f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "val_percent_size = 0.20\n",
    "test_percent_size = 0.20\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=test_percent_size, random_state=0\n",
    ")  # We keep 20% of data set to test\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=val_percent_size, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980fe21-fe7a-466a-b250-bbce167736a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The number of sample for training, validation and test are {X_train.shape[0]}, {X_test.shape[0]}, {X_test.shape[0]}, respectively.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b30bc-6278-4265-a42d-d48bb8b1f46b",
   "metadata": {},
   "source": [
    "We transform numpy array to pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b9f03-203e-40e2-b854-b1c92cb314d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = torch.from_numpy(X_train).to(torch.float32), torch.from_numpy(\n",
    "    y_train\n",
    ").to(torch.float32).unsqueeze(1)\n",
    "X_val, y_val = torch.from_numpy(X_val).to(torch.float32), torch.from_numpy(y_val).to(\n",
    "    torch.float32\n",
    ").unsqueeze(1)\n",
    "X_test, y_test = torch.from_numpy(X_test).to(torch.float32), torch.from_numpy(\n",
    "    y_test\n",
    ").to(torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b706142-0fb7-443f-a16b-0c8e52e93c47",
   "metadata": {},
   "source": [
    "We now define the pytorch dataloaders that will be used during the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1598a2e5-9279-46a5-9c89-c9effd78c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_set = DataLoader(\n",
    "    TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True\n",
    ")\n",
    "val_set = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size, shuffle=True)\n",
    "test_set = DataLoader(\n",
    "    TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e3b9a-9ce7-4770-896a-92c8accad6ef",
   "metadata": {},
   "source": [
    "# Define the Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617f004-db5f-4dae-a710-84bc97dbbee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_size: int = 1):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, X: torch.tensor):\n",
    "        out = self.linear1(X)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24f55b6-e5bf-4af4-adab-6fce132851a3",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "As for the linear 1D model, we need to define the optimizer and iterate over the train set. We add a new step, wich computes the loss function on the validation data set to monitor the convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadda7be-2e9a-456e-b8a7-2346d1b8a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "model = RegressionModel(input_size=X_train.shape[1])\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71651dc8-a1be-4747-a8a4-cbb98670cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "train_set_len = len(train_set)\n",
    "val_set_len = len(val_set)\n",
    "train_loss, val_loss = [], []\n",
    "for epoch in range(n_epochs):\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "    accu = 0.0\n",
    "    for X_, y_ in train_set:\n",
    "        # Forward pass\n",
    "        y_hat = model(X_)\n",
    "        loss = loss_fn(y_hat, y_)\n",
    "        accu += loss.item()\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss.append(accu / train_set_len)\n",
    "\n",
    "    # Validation - no gradient & eval mode\n",
    "    # https://pytorch.org/docs/stable/generated/torch.no_grad.html\n",
    "    # https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval\n",
    "    model.eval()\n",
    "    accu = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_, y_ in val_set:\n",
    "            # Forward pass\n",
    "            y_hat = model(X_)\n",
    "            loss = loss_fn(y_hat, y_)\n",
    "            accu += loss.item()\n",
    "        val_loss.append(accu / val_set_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b0e74-2733-4ab7-97f3-689d173e7553",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(train_loss)\n",
    "plt.semilogy(val_loss)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7f1000-831a-4669-aca8-bc75af1d2693",
   "metadata": {},
   "source": [
    "# Do the prediction\n",
    "We perform the prediction on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16070e1-c94d-4c9c-b9da-e7c003488bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_ = model(X_test)\n",
    "print(f\"MSE on the test set: {loss_fn(y_test, y_).item()}\")\n",
    "print(f\"R2 on the test set: {r2_score( y_.detach().numpy(), y_test.detach().numpy())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2aaca2-aa08-497f-b972-0364704b5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatter plot: prediction as a function of the true values\n",
    "plt.scatter(y_test.detach().numpy(), y_.detach().numpy())\n",
    "plt.xlim([y_test.detach().numpy().min(), y_test.detach().numpy().max()])\n",
    "plt.ylim([y_test.detach().numpy().min(), y_test.detach().numpy().max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3d80a7-6dfd-48a1-b548-ea297ec9f925",
   "metadata": {},
   "source": [
    "# TO DO\n",
    "- Play a little bit with the hyperparameters (learning_rate, batch_size) to improve the accuarcy\n",
    "- Change the MSE to L1 loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
