{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc656dc-ddfd-4a95-856f-f5a7da7fa3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35affe2d-05b4-496e-9bb9-c835b0f8aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308e607d-8060-4551-bfcf-ccc3500f3bd2",
   "metadata": {},
   "source": [
    "We start by generating a toy 2D linear problem: $y = 10x_1 + 20x_2$.\n",
    "\n",
    "The second feature has a dynamic that is 10 times larger than the first feature:\n",
    "- $x_1 \\sim \\mathcal{N}(0,1)$\n",
    "- $x_2 \\sim \\mathcal{N}(10,10)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b0d3ce-f6fd-4a49-b951-a87fcd1683eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_problem(scaler: StandardScaler = None, random_seed=0) -> (np.array, ...):\n",
    "    # Generate data with feature of different scale\n",
    "    np.random.seed(random_seed)\n",
    "    w_true = np.asarray([10, 30])\n",
    "    w_hat = w_true + 10 * np.random.randn(2)\n",
    "\n",
    "    X = np.random.randn(100, 2) * np.asarray([1, 10]) + np.asarray([0, 10])\n",
    "\n",
    "    y_true = X @ w_true\n",
    "    y_hat = X @ w_hat\n",
    "    e = (y_true - y_hat)[:, np.newaxis]\n",
    "    if (\n",
    "        scaler is not None\n",
    "    ):  # https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "        X = scaler.fit_transform(X)\n",
    "    return X, y_true, y_hat, e, w_true, w_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e886dd-ee29-4b04-9e8b-227e769592e8",
   "metadata": {},
   "source": [
    "Helper function for plotting the iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb4ef86-0d2d-492b-94f9-e00ae6574c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iterations(W: list, w_true: np.array, scaler: StandardScaler = None) -> None:\n",
    "    Wa = np.asarray(W)\n",
    "    if (\n",
    "        scaler is not None\n",
    "    ):  # Should descale the parameter to be in the same dynamic than the original\n",
    "        Wa /= scaler.scale_\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(Wa[:, 0], Wa[:, 1], c=range(n_epochs + 1))\n",
    "    plt.scatter(w_true[0], w_true[1], marker=\"*\")\n",
    "    for e, (w_1, w_2) in enumerate(Wa):\n",
    "        plt.annotate(\n",
    "            str(e), (w_1, w_2), textcoords=\"offset points\", xytext=(0, 10), ha=\"center\"\n",
    "        )\n",
    "    plt.xlabel(\"w_1\")\n",
    "    plt.ylabel(\"w_2\")\n",
    "    plt.title(f\"True W: {w_true}\")\n",
    "    plt.xlim([9, 30])\n",
    "    plt.ylim([3, 60])\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df962487-893b-4516-bfe9-e5aea666fc3c",
   "metadata": {},
   "source": [
    "We can now look at the iteration process with differnt learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e22e7d-6ebe-4660-bb63-c950084bb9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "scale = False\n",
    "scaler = StandardScaler() if scale else None\n",
    "\n",
    "for learning_rate in [0.001, 0.01, 0.05]:\n",
    "    X, y_true, y_hat, e, w_true, w_hat = init_problem(scaler=scaler)\n",
    "    W = [w_hat.copy()]\n",
    "    for epoch in range(n_epochs):\n",
    "        e = (y_true - X @ w_hat)[:, np.newaxis]\n",
    "        grad = -np.mean(e * X, axis=0)\n",
    "        w_hat -= learning_rate * grad\n",
    "        W.append(w_hat.copy())\n",
    "    plot_iterations(W, w_true, scaler=scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9b8033-e78b-4c2d-a72f-073eedcf73f9",
   "metadata": {},
   "source": [
    "You can have a look to the gradiant values also: should exhibit different dynamics w.r.t. scaling. This is let as homework :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc7a8d-b411-4651-af19-3061fc46ae40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
