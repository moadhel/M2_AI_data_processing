{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eefe240",
   "metadata": {},
   "source": [
    "# Construire et entraîner un processus gaussien via l'objet _class_ de python\n",
    "\n",
    "L'objectif de ce TP est double : \n",
    "- apprendre un modèle de processus gaussien à partir de données (régression)\n",
    "- se familiariser avec l'objet ```class``` de python\n",
    "\n",
    "Voir https://courspython.com/classes-et-objets.html pour une introduction aux classes.\n",
    "\n",
    "Version originale : Felipe Tobar, Adapté pour IATI par Elsa Cazelles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e852fa18",
   "metadata": {},
   "source": [
    "#### Le processus gaussien\n",
    "\n",
    "Dans ce TP, nous considèrerons un noyau de mélange spectral, défini pour deux vecteurs de même taille $x$ et $x'$, et trois paramètres $\\gamma, \\mu$ et $\\sigma$, par:\n",
    "\n",
    "$$\\text{Spec_Mix}(x, x', \\gamma, \\mu, \\sigma) = \\sigma^2 * \\exp(-\\gamma \\Vert x-x'\\Vert^2)\\cos(2\\pi\\mu\\Vert x-x'\\Vert).$$\n",
    "\n",
    "Le modèle de régression considéré est alors le suivant:\n",
    "\n",
    "$$y \\sim \\mathcal{GP}(m,K),$$\n",
    "avec\n",
    "$$K(x,x') = \\text{Spec_Mix}(x, x', \\gamma, \\mu, \\sigma) + \\sigma^2_{\\text{noise}}\\text{Id}.$$\n",
    "\n",
    "Le vecteur de paramètres est donc donné par\n",
    "\n",
    "$$\\theta = (???).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a955a6",
   "metadata": {},
   "source": [
    "Commençons par importer les modules nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3906cd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T20:13:54.208142Z",
     "start_time": "2021-12-06T20:13:53.717385Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b81e3",
   "metadata": {},
   "source": [
    "**Exercice :**\n",
    "Créer un fichier **outils.py**, dans lequel vous définirez le noyau **Spec_Mix($x_1, x_2, \\gamma, \\mu, \\sigma$)**.\n",
    "\n",
    "Pour cela, utiliser la bibliothèque **numpy**.\n",
    "\n",
    "**Remarque :** pour le calcul de $\\Vert x_1-x_2\\Vert$, utiliser la fonction ```np.outer```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fbb296",
   "metadata": {},
   "source": [
    "Nous allons maintenant contruire la classe **gp_class**, au fur et à mesure du TP, en y ajoutant des fonctions. En premier lieu, importer la classe en l'appelant dans la variable **gp**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865fc31e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T20:13:54.792800Z",
     "start_time": "2021-12-06T20:13:54.779679Z"
    }
   },
   "outputs": [],
   "source": [
    "from gp_class import *\n",
    "\n",
    "gp = gp_class()\n",
    "gp.init_hypers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e76b3f5",
   "metadata": {},
   "source": [
    "Regarder comment se présente la fonction classe dans **gp_class.py**, ainsi que les variables enregistrées dans la classe. Avons-nous des données?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a704372",
   "metadata": {},
   "source": [
    "Nous allons construire la fonction ```calcul_posterieur```, qui renvoie la moyenne et la covariance du GP.\n",
    "- Dans un premier temps, nous n'avons aucune données, la moyenne est considérée nulle, et la covariance du GP est tirée selon une grille pré-définie. Nous pouvons toujours générer plusieurs trajectoires du processus gaussien.\n",
    "- Dans un second temps, nous avons accès à des données, et la moyenne et la covariance du GP a posteriori dépendront de ces données.\n",
    "\n",
    "\n",
    "#### Compléter la fonction suivante et l'ajouter à la classe ```gp_class```:\n",
    "\n",
    "```\n",
    "def compute_posterior(self, dimension=None, where=None):\n",
    "\n",
    "    if dimension is None:\n",
    "        self.N = 100\n",
    "        self.time = np.linspace(1, 100, 100)\n",
    "    elif np.size(dimension) == 1:\n",
    "        self.N = dimension\n",
    "        self.time = np.linspace(1, 100, dimension)\n",
    "    if where is not None:\n",
    "        self.time = where\n",
    "        self.N = len(where)\n",
    "\n",
    "    cov_grid = Spec_Mix(self.time, self.time, ..., ..., ...,) + 1e-5*np.eye(self.N)+self.sigma_n**2*np.eye(self.N)\n",
    "\n",
    "    if self.x is None:  # nous n'avons aucune observations\n",
    "        self.mean = np.zeros_like(self.time)\n",
    "        self.cov = cov_grid\n",
    "    else:  # nous avons accès à des observations\n",
    "        cov_obs = Spec_Mix(self.x, self.x, ..., ..., ...) + 1e-5*np.eye(self.Nx) + self.sigma_n**2*np.eye(self.Nx)\n",
    "        cov_star = Spec_Mix(..., ..., ..., ..., ...)\n",
    "        self.mean = np.squeeze(cov_star@np.linalg.solve(cov_obs, ...))\n",
    "        self.cov = cov_grid - (cov_star@np.linalg.solve(cov_obs, cov_star.T))\n",
    "            \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51421720",
   "metadata": {},
   "source": [
    "**Remarque :** lorsqu'on modifie un object classe, il faut le recharger dans le notebook jupyter. Pour cela, vous avez deux options:\n",
    "\n",
    "1 :\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "reload(gp_class)\n",
    "\n",
    "\n",
    "2 :\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "import gp_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c3a490",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T20:13:55.732880Z",
     "start_time": "2021-12-06T20:13:55.469633Z"
    }
   },
   "outputs": [],
   "source": [
    "gp.compute_posterior(dimension=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3636fb",
   "metadata": {},
   "source": [
    "Qu'à fait cette fonction?\n",
    "\n",
    "Générer ensuite des échantillons via la fonction **sample** dans la classe **gp**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5090c57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T20:13:55.732880Z",
     "start_time": "2021-12-06T20:13:55.469633Z"
    }
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d39ccac",
   "metadata": {},
   "source": [
    "Tracer ensuite les trajectoires des ces échantillons, via la fonction plot_samples présente dans la classe **gp**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e3d81a",
   "metadata": {},
   "source": [
    "#### Donnons nous maintenant des observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd90ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T20:13:56.466436Z",
     "start_time": "2021-12-06T20:13:56.344931Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Produire les données\n",
    "N = 120\n",
    "x = 100*np.random.random(N) + 0.1*np.random.randn(N)\n",
    "y = 20*np.cos(1.5*x)*np.cos(0.1*x) + 0.1*np.random.randn(N)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cf77bf",
   "metadata": {},
   "source": [
    "- Charger les données dans la classe gp.\n",
    "- Utiliser une fonction de la classe pour afficher les données sur un graphique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adde5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aac4f0",
   "metadata": {},
   "source": [
    "Calculer de nouveau le GP a posteriori à partir des données $x$ et $y$. Ensuite générer et tracer 5 trajectoires de processus gaussien correspondant à ces données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c45c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T20:13:57.397472Z",
     "start_time": "2021-12-06T20:13:56.770001Z"
    }
   },
   "outputs": [],
   "source": [
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7751c",
   "metadata": {},
   "source": [
    "Calculer la log-vraissemblance négative en complétant le code ci-dessous et en l'incluant dans la classe **gp**.\n",
    "\n",
    "```\n",
    "def nll(self):\n",
    "    Y = ...\n",
    "    Gram = Spec_Mix(..., ..., ..., ..., ...)\n",
    "    K = ...\n",
    "    (sign, logdet) = np.linalg.slogdet(...)\n",
    "    return ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Log-vraissemblance négative: {gp.nll()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db94e29e",
   "metadata": {},
   "source": [
    "## Entraînement des hyper-paramètres du processus gaussien\n",
    "\n",
    "Pour cela, nous allons utiliser la fonction ```minimize```de ```scipy.optimize```, qui optimisera les hyper-paramètres par descente de gradient. Nous allons donc définir deux fonctions dans la classe gp:\n",
    "- la fonction de la log-vraisemblance négative ```nlogp```, très proche de ```nll```mais qui prend en entrée les hyperparamètres à optimiser:\n",
    "```\n",
    "def nlogp(self, hypers):\n",
    "    sigma = np.exp(hypers[0])\n",
    "    gamma = np.exp(hypers[1])\n",
    "    mu = np.exp(hypers[2])\n",
    "    sigma_n = np.exp(hypers[3])\n",
    "\n",
    "    Y = ...\n",
    "    Gram = ...\n",
    "    K = ...\n",
    "    (sign, logdet) = ...\n",
    "    return ...\n",
    "```\n",
    "\n",
    "- la fonction qui retourne le gradient de ```nlogp``` en fonction des hyperparamètres\n",
    "```\n",
    "def dnlogp(self, hypers):\n",
    "    sigma = np.exp(hypers[0])\n",
    "    gamma = np.exp(hypers[1])\n",
    "    mu = np.exp(hypers[2])\n",
    "    sigma_n = np.exp(hypers[3])\n",
    "\n",
    "    Y = ...\n",
    "    Gram = Spec_Mix(..., ..., ..., ..., ...)\n",
    "    K = ...\n",
    "    ## h est le résultat de $(K^{-1}Y).T$\n",
    "    h = np.linalg.solve(., .).T\n",
    "\n",
    "    ## Dérivées par rapport aux paramètres\n",
    "    dKdsigma = ...\n",
    "    dKdgamma = ...\n",
    "    dKdmu = ...\n",
    "    dKdsigma_n = ...\n",
    "\n",
    "    H = (np.outer(h, h) - np.linalg.inv(K))\n",
    "    dlogp_dsigma = ...\n",
    "    dlogp_dgamma = ...\n",
    "    dlogp_dmu = ...\n",
    "    dlogp_dsigma_n = ...\n",
    "    return np.array([dlogp_dsigma, dlogp_dgamma, dlogp_dmu, dlogp_dsigma_n])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a802a7fc",
   "metadata": {},
   "source": [
    "On peut alors entraîner le modèle via la fonction suivante (à ajouter dans la classe **gp**):\n",
    "\n",
    "```\n",
    "def train(self, flag='quiet'):\n",
    "    hypers0 = np.array([np.log(self.sigma), np.log(self.gamma), np.log(self.mu), np.log(self.sigma_n)])\n",
    "    res = minimize(self.nlogp, hypers0, args=(), method='L-BFGS-B',\n",
    "                   jac=self.dnlogp, options={'maxiter': 500, 'disp': True})\n",
    "    self.sigma = np.exp(res.x[0])\n",
    "    self.gamma = np.exp(res.x[1])\n",
    "    self.mu = np.exp(res.x[2])\n",
    "    self.sigma_n = np.exp(res.x[3])\n",
    "    self.theta = np.array([self.mu, self.gamma, self.sigma_n])\n",
    "    if flag != 'quiet':\n",
    "        print('Hyperparameters are:')\n",
    "        print(f'sigma ={self.sigma}')\n",
    "        print(f'gamma ={self.gamma}')\n",
    "        print(f'mu ={self.mu}')\n",
    "        print(f'sigma_n ={self.sigma_n}')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc0f06e",
   "metadata": {},
   "source": [
    "Effectuer ensuite l'apprentissage des hyperparamètres dans la fonction précédente et afficher la valeur des paramètres après entraînement (via une fonction de la classe **gp**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fffe05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T20:13:57.686999Z",
     "start_time": "2021-12-06T20:13:57.401173Z"
    }
   },
   "outputs": [],
   "source": [
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dcd557",
   "metadata": {},
   "source": [
    "On peut de nouveau calculer le postérieur et l'évaluer en de nouveaux points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc53a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T20:13:58.559038Z",
     "start_time": "2021-12-06T20:13:57.689282Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b022d27",
   "metadata": {},
   "source": [
    "On remarque également que la log-vraisemblance négative est minimisée après entraînement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'negative log-likelihood: {gp.nll()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe097c9",
   "metadata": {},
   "source": [
    "## Exemple sur un jeu de données réelles : fréquence cardiaque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743896c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement et préparation des données\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "signal = np.loadtxt('hr1.txt') \n",
    "time = (np.linspace(0, 1800,1800))\n",
    "time_label = 'temps'\n",
    "signal_label = 'Fréquence cardiaque'\n",
    "        \n",
    "# On centre le signal\n",
    "signal = signal - np.mean(signal)\n",
    "\n",
    "N_obs = 400 # on choisit un nombre de d'observation sur les 1800 disponibles\n",
    "indices = np.arange(len(signal))\n",
    "np.random.shuffle(indices)\n",
    "indices = indices[:N_obs]\n",
    "indices = np.sort(indices)\n",
    "signal_init = signal[indices]\n",
    "time_init = time[indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fe1c2b",
   "metadata": {},
   "source": [
    "#### Effectuer la même analyse que précédemment sur ce jeu de données, en précisant les étapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2181560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94efbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d2be20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da741a44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
